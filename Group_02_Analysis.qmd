---
title: "Group_02_Analysis"
author: "Group 02"
format:
  pdf:
    output-file: "Group_02_Analysis"
    output-ext: "pdf"
execute:
  echo: true
  eval: true
  warning: false
  message: false
output:
  pdf_document:
    fig_caption: yes
---

```{r}
library(jsonlite)
library(dplyr)
library(tidyr)
library(sjPlot)
library(janitor)
library(ggplot2)
library(readr)
library(corrplot)
library(MASS)
library(car)
```

# Data

In this project, we used a dataset to study the impact of other variables on Total.Number.of.Family.members. Next, we will use a series of methods to identify a few suitable variables to begin research and perform GLM fitting and evaluation. These variables include Total.Food.Expenditure, Household.Head.Sex, and Type.of.Household.

```{r}
Data <- read.csv("dataset02.csv")
Data <- Data %>% dplyr::select(-Region)#Elements are duplicated
```

# Data Exploration

In order to identify a few suitable research variables for easier study, we will use functions like cor, ANOVA, and others to select two appropriate numerical variables and one categorical variable.
```{r}
# Ensure Electricity is treated as a categorical variable
Data$Electricity <- as.factor(Data$Electricity)

# Select numerical variables.
num_vars <- c("Total.Household.Income", 
              "Total.Food.Expenditure", 
              "Household.Head.Age",
              "Total.Number.of.Family.members", 
              "House.Floor.Area", 
              "House.Age",
              "Number.of.bedrooms")

# Calculate the correlation of numerical variables
cor_matrix <- cor(Data[num_vars], use = "complete.obs")
cor_family <- cor_matrix[, "Total.Number.of.Family.members"]

#Select the two most correlated elements
top_2_numeric <- names(sort(abs(cor_family), decreasing = TRUE)[2:3])

# Select categorical variables
cat_vars <- c( "Household.Head.Sex", 
               "Type.of.Household", 
               "Electricity")

# Calculate ANOVA p-value
anova_results <- lapply(cat_vars, function(var) {
  anova_res <- aov(Total.Number.of.Family.members ~ Data[[var]], data = Data)
  summary(anova_res)[[1]][["Pr(>F)"]][1]  # Extracting p-value
})
anova_results <- unlist(anova_results)
```
We have decided to select the two most correlated numerical variables and the categorical variable with the smallest p-value as our research subjects.

The three selected variables are: **Total.Food.Expenditure, Household.Head.Age, and Type.of.Household.**

```{r}
Data <- Data %>%
  dplyr::select(Total.Food.Expenditure, Household.Head.Age, Type.of.Household, Total.Number.of.Family.members)
```

# Variable Distribution Visualization

Next, we will perform visualization to better understand how to process the data in the following sections and which models to use for fitting. Through visualization, we can gain insights into the relationships between variables, detect potential outliers, and decide on the most suitable modeling approach.
```{r}
#| label: fig-His_TFE
#| fig-cap: Histogram of Total.Food.Expenditure
#| fig-align: center
#| fig.pos: H
# Histogram of Total.Food.Expenditure
ggplot(Data, aes(x = Total.Food.Expenditure)) +
  geom_histogram(aes(y = ..density..), bins = 30, fill = "lightblue", color = "black", alpha = 0.7) +
  geom_density(color = "red", linewidth = 1) +
  labs(title = "Distribution of Total Food Expenditure", x = "Total Food Expenditure", y = "Density")
```
The variable distribution of Total.Food.Expenditure is highly right-skewed (long right tail), meaning that most households have low food expenditures, but there are some extremely high values.

```{r}
#| label: fig-His_HHA
#| fig-cap: Histogram of Household.Head.Age
#| fig-align: center
#| fig.pos: H
# Histogram of Household.Head.Age
ggplot(Data, aes(x = Household.Head.Age)) +
  geom_histogram(aes(y = ..density..), bins = 30, fill = "lightgreen", color = "black", alpha = 0.7) +
  geom_density(color = "blue", linewidth = 1) +
  labs(title = "Distribution of Household Head Age", x = "Household Head Age", y = "Density")
```
The distribution of Household.Head.Age is approximately normal.The data is well-distributed and can be used directly.

```{r}
#| label: fig-Bar_TOH
#| fig-cap: Bar chart of Type.of.Household
#| fig-align: center
#| fig.pos: H
# Bar chart of Type.of.Household
ggplot(Data, aes(x = Type.of.Household, fill = Type.of.Household)) +
  geom_bar() +
  labs(title = "Count of Household Types", x = "Household Type", y = "Count") +
  theme(legend.position = "none")
```
We can easily observe that the "Two or More Nonrelated Persons/Members" category has very few samples, which may affect model stability in GLM fitting.

```{r}
#| label: fig-Box_TOHVSTNOFM
#| fig-cap: Box plot of Type.of.Household and Total.Number.of.Family.members
#| fig-align: center
#| fig.pos: H
# Box plot of the relationship between 'Type.of.Household' and 'Total.Number.of.Family.members'
ggplot(Data, aes(x = Type.of.Household, y = Total.Number.of.Family.members)) +
  geom_boxplot() +
  labs(title = "Household Type vs. Family members")
```
From the above figure, we can see that Extended Family usually has the highest number of family members, Single Family has fewer, and households with nonrelated persons have the least. However, there are outliers present. In the subsequent data processing, we will consider using the IQR method to remove these outliers.

```{r}
#| label: fig-His_HHAVsTNOFM
#| fig-cap: Histogram of Household.Head.Age vs. Total.Number.of.Family.members
#| fig-align: center
#| fig.pos: H
# check the relationship between independent variable with dependent variable（Household.Head.Age vs. Total.Number.of.Family.members）
ggplot(Data, aes(x = Household.Head.Age, y = Total.Number.of.Family.members)) +
  geom_point() +
  geom_smooth(method = "loess") +
  labs(title = "Age of Household Head vs. Family members")
```
The LOESS curve exhibits a nonlinear trend (first rising and then falling), whereas Poisson regression assumes a linear relationship. Therefore, we will consider polynomial regression in the subsequent model construction. Additionally, there are some outliers that we may consider removing.

```{r}
#| label: fig-His_TNOFM
#| fig-cap: Histogram of Total.Number.of.Family.members
#| fig-align: center
#| fig.pos: H
# Histogram of Total.Number.of.Family.members
ggplot(Data, aes(x = Total.Number.of.Family.members)) +
  geom_histogram(aes(y = ..density..), bins = 30, fill = "pink", color = "black", alpha = 0.7) +
  geom_density(color = "green", linewidth = 1) +
  labs(title = "Distribution of Total Number of Family members", x = "Total.Number.of.Family.members", y = "Density")
```
We found that the data is right-skewed and contains a few high-member outliers. We will consider whether to remove these outliers.

# **Data Preprocessing**

```{r}
#Ensure the variable types are correct.
Data$Total.Food.Expenditure <- as.numeric(Data$Total.Food.Expenditure)
Data$Household.Head.Age <- as.numeric(Data$Household.Head.Age)
Data$Total.Number.of.Family.members <- as.numeric(Data$Total.Number.of.Family.members)
Data$Type.of.Household <- as.factor(Data$Type.of.Household)
```

```{r}
#| label: fig-His_log_TFE
#| fig-cap: Histogram of log_Total.Food.Expenditure
#| fig-align: center
#| fig.pos: H
Data <- Data |> mutate(log_Total.Food.Expenditure = log(Total.Food.Expenditure + 1))
# Histogram of log_Total.Food.Expenditure
ggplot(Data, aes(x = log_Total.Food.Expenditure)) +
  geom_histogram(aes(y = ..density..), bins = 30, fill = "lightblue", color = "black", alpha = 0.7) +
  geom_density(color = "red", linewidth = 1) +
  labs(title = "Distribution of Log Total Food Expenditure", x = "Log Total Food Expenditure", y = "Density")
```
It is evident that the data follows a normal distribution more closely after applying the logarithm transformation, achieving our goal. Next, we will consider using this transformed data for model fitting.

# Modeling with GLM Poisson, Negative binomial and Gamma regression

```{r}
# Perform Poisson regression using GLM 
poisson_model <- glm(Total.Number.of.Family.members ~ Total.Food.Expenditure + Household.Head.Age + Type.of.Household, 
                 data = Data, 
                 family = poisson())
summary(poisson_model)
```

Total.Food.Expenditure has a p-value \< 2e-16, indicating that it is statistically significant. Household.Head.Age has a p-value \< 2e-16, indicating that it is statistically significant. Type.of.Household has a p-value = 0.0122, indicating that it is statistically significant, however, the effect size is relatively small. Next, we will consider Negative Binomial Regression.

```{r}
# Modeling with GLM Negative binomial regression
nb_model <- glm.nb(Total.Number.of.Family.members ~ 
                    Total.Food.Expenditure + 
                    Household.Head.Age + 
                    Type.of.Household,
                  data = Data)
summary(nb_model)
```

```{r}
#Perform Gamma regression using GLM modeling.
# check if the dependent all over 0
summary(Data$Total.Number.of.Family.members)

gamma_model <- glm(Total.Number.of.Family.members ~ Total.Food.Expenditure + Type.of.Household + Household.Head.Age,
                   data = Data,
                   family = Gamma(link = "log"))

summary(gamma_model)
```

After obtaining three different models, we consider adding the previously log-transformed data.
```{r}
# Perform Poisson regression using GLM (log_Total.Food.Expenditure)
poisson_model <- glm(Total.Number.of.Family.members ~ log_Total.Food.Expenditure + Household.Head.Age + Type.of.Household, 
                 data = Data, 
                 family = poisson())
summary(poisson_model)
```
It can be observed that the p-values improve to varying degrees. Therefore, we mainly focus on the first three models.

# GLM Regression Analysis Results

```{r}
# Compare the AIC of Poisson and negative binomial models and gamma models
AIC<-AIC(poisson_model, nb_model, gamma_model)
AIC

#Compare Poisson with negative binomial models
lmtest::lrtest(poisson_model, nb_model)

# Coefficient to explain negative binomial regression (incidence ratio IRR)
exp(coef(nb_model))

#check Overdispersion
cat("Overdispersion =", poisson_model$deviance / poisson_model$df.residual)

# Check collinearity (high collinearity results in unstable coefficients)
vif(poisson_model)

plot(nb_model, which = 1)  # Residual vs fit value

```
By comparing the AIC values of the three models,it can be seen that model Gamma has the lowest AIC value.It shows that the gamma model fits the data better.But the dependent variable 'the Total Number of Family' is a count data not suitable for gamma model Although it has a lower AIC number. 
So we back to Poisson and negative binomial models. For the AIC value of the poisson model is lower and after compared with the two models p valve(0.9075) is not lower than 0.05 so we should not change the poisson model into negative binomial model.
For the poisson model its Overdispersion = 0.7947643 close to 1 that shows the data not Significant overdispersion.The IRR part shows IRR(Total.Food.Expenditure)=1.0000033 effect can be ignored,IRR(Household.Head.Age)=0.991 weakly negative effect,IRR(Type.of.Household_Single Family)= 0.706,IRR(Two or More Nonrelated Persons)= 0.542 the type of family is the key factor affecting the number of family members, and the reduction effect of multiple non-relatives is the most significant.
The GVIF values of all variables are close to 1, and the adjusted values are all < 1.04, indicating that there is no multicollinearity problem and the model coefficients are reliable.