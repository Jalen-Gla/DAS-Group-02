---
title: "Group_02_Analysis"
author: "Group 02"
format:
  pdf:
    output-file: "Group_02_Analysis"
    output-ext: "pdf"
execute:
  echo: false
  eval: true
  warning: false
  message: false
output:
  pdf_document:
    fig_caption: yes
---

```{r}
library(jsonlite)
library(dplyr)
library(tidyr)
library(sjPlot)
library(janitor)
library(ggplot2)
library(readr)
library(corrplot)
library(MASS)
library(car)
```

# Data

```{r}
Data <- read.csv("dataset02.csv")
Data <- Data %>% dplyr::select(-Region)#Elements are duplicated
```

# Data Exploration

```{r}
# Ensure Electricity is treated as a categorical variable
Data$Electricity <- as.factor(Data$Electricity)

# Select numerical variables.
num_vars <- c("Total.Household.Income", 
              "Total.Food.Expenditure", 
              "Household.Head.Age",
              "Total.Number.of.Family.members", 
              "House.Floor.Area", 
              "House.Age",
              "Number.of.bedrooms")

# Calculate the correlation of numerical variables
cor_matrix <- cor(Data[num_vars], use = "complete.obs")
cor_family <- cor_matrix[, "Total.Number.of.Family.members"]

#Select the two most correlated elements
top_2_numeric <- names(sort(abs(cor_family), decreasing = TRUE)[2:3])

# Select categorical variables
cat_vars <- c( "Household.Head.Sex", 
               "Type.of.Household", 
               "Electricity")

# Calculate ANOVA p-value
anova_results <- lapply(cat_vars, function(var) {
  anova_res <- aov(Total.Number.of.Family.members ~ Data[[var]], data = Data)
  summary(anova_res)[[1]][["Pr(>F)"]][1]  # Extracting p-value
})
anova_results <- unlist(anova_results)
```

We have decided to select the two most correlated numerical variables and the categorical variable with the smallest p-value as our research subjects.

The three selected variables are: **Total.Food.Expenditure, Household.Head.Age, and Type.of.Household.**

```{r}
Data <- Data %>%
  dplyr::select(Total.Food.Expenditure, Household.Head.Age, Type.of.Household, Total.Number.of.Family.members)
```

# Variable Distribution Visualization

```{r}
# Histogram of Total.Food.Expenditure
ggplot(Data, aes(x = Total.Food.Expenditure)) +
  geom_histogram(aes(y = ..density..), bins = 30, fill = "lightblue", color = "black", alpha = 0.7) +
  geom_density(color = "red", linewidth = 1) +
  labs(title = "Distribution of Total Food Expenditure", x = "Total Food Expenditure", y = "Density")
```

The variable distribution of Total.Food.Expenditure is highly right-skewed (long right tail), meaning that most households have low food expenditures, but there are some extremely high values.

```{r}
# Histogram of Household.Head.Age
ggplot(Data, aes(x = Household.Head.Age)) +
  geom_histogram(aes(y = ..density..), bins = 30, fill = "lightgreen", color = "black", alpha = 0.7) +
  geom_density(color = "blue", linewidth = 1) +
  labs(title = "Distribution of Household Head Age", x = "Household Head Age", y = "Density")
```

The distribution of Household.Head.Age is approximately normal.The data is well-distributed and can be used directly.

```{r}
# Bar chart of Type.of.Household
ggplot(Data, aes(x = Type.of.Household, fill = Type.of.Household)) +
  geom_bar() +
  labs(title = "Count of Household Types", x = "Household Type", y = "Count") +
  theme(legend.position = "none")
```

We can easily observe that the "Two or More Nonrelated Persons/Members" category has very few samples, which may affect model stability in GLM fitting.

```{r}
# Box plot of the relationship between 'Type.of.Household' and 'Total.Number.of.Family.members'
ggplot(Data, aes(x = Type.of.Household, y = Total.Number.of.Family.members)) +
  geom_boxplot() +
  labs(title = "Household Type vs. Family members")
```

From the above figure, we can see that Extended Family usually has the highest number of family members, Single Family has fewer, and households with nonrelated persons have the least. However, there are outliers present. In the subsequent data processing, we will consider using the IQR method to remove these outliers.

```{r}
# check the relationship between independent variable with dependent variable（Household.Head.Age vs. Total.Number.of.Family.members）
ggplot(Data, aes(x = Household.Head.Age, y = Total.Number.of.Family.members)) +
  geom_point() +
  geom_smooth(method = "loess") +
  labs(title = "Age of Household Head vs. Family members")
```

The LOESS curve exhibits a nonlinear trend (first rising and then falling), whereas Poisson regression assumes a linear relationship. Therefore, we will consider polynomial regression in the subsequent model construction. Additionally, there are some outliers that we may consider removing.

```{r}
# Histogram of Total.Number.of.Family.members
ggplot(Data, aes(x = Total.Number.of.Family.members)) +
  geom_histogram(aes(y = ..density..), bins = 30, fill = "pink", color = "black", alpha = 0.7) +
  geom_density(color = "green", linewidth = 1) +
  labs(title = "Distribution of Total Number of Family members", x = "Total.Number.of.Family.members", y = "Density")
```

We found that the data is right-skewed and contains a few high-member outliers. We will consider whether to remove these outliers.

# **Data Preprocessing**

```{r}
#Ensure the variable types are correct.
Data$Total.Food.Expenditure <- as.numeric(Data$Total.Food.Expenditure)
Data$Household.Head.Age <- as.numeric(Data$Household.Head.Age)
Data$Total.Number.of.Family.members <- as.numeric(Data$Total.Number.of.Family.members)e
Data$Type.of.Household <- as.factor(Data$Type.of.Household)
```

# Modeling with GLM Poisson regression

```{r}
# Perform Poisson regression using GLM 
possion_model <- glm(Total.Number.of.Family.members ~ Total.Food.Expenditure + Household.Head.Age + Type.of.Household, 
                 data = Data, 
                 family = poisson())
summary(possion_model)
```

Total.Food.Expenditure has a p-value \< 2e-16, indicating that it is statistically significant. Household.Head.Age has a p-value \< 2e-16, indicating that it is statistically significant. Type.of.Household has a p-value = 0.0122, indicating that it is statistically significant, however, the effect size is relatively small. Next, we will consider Negative Binomial Regression.

```{r}
# Modeling with GLM Negative binomial regression
nb_model <- glm.nb(Total.Number.of.Family.members ~ 
                    Total.Food.Expenditure + 
                    Household.Head.Age + 
                    Type.of.Household,
                  data = Data)
summary(nb_model)
```

```{r}
#Perform Gamma regression using GLM modeling.
# check if the dependent all over 0
summary(Data$Total.Number.of.Family.members)

gamma_model <- glm(Total.Number.of.Family.members ~ Total.Food.Expenditure + Type.of.Household + Household.Head.Age,
                   data = Data,
                   family = Gamma(link = "log"))

summary(gamma_model)
```

# GLM Regression Analysis Results

```{r}
# Compare the AIC of Poisson and negative binomial models and gamma models
AIC(poisson_model, nb_model, gamma_model)

# Coefficient to explain negative binomial regression (incidence ratio IRR)
exp(coef(nb_model))

#check Overdispersion
cat("Overdispersion =", poisson_model$deviance / poisson_model$df.residual)

plot(poisson_model, which = 1)  # Residual vs fit value
qqnorm(resid(poisson_model))    # Normality test

# Check collinearity (high collinearity results in unstable coefficients)
vif(poisson_model) 
```
